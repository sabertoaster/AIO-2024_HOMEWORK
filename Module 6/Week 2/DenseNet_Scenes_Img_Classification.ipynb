{"cells":[{"cell_type":"markdown","metadata":{"id":"Ls3L9w-mG9Zq"},"source":["## **0. Download dataset**\n","**Note:** If you can't download using gdown due to limited number of downloads, please download it manually and upload it to your drive, then copy it from the drive to colab.\n","```python\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","!cp /path/to/dataset/on/your/drive .\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XR2hDC-kBMyd"},"outputs":[],"source":["# https://drive.google.com/file/d/1ZUCuYDOe4VVbZvNVZovpquaRQqqJQ639/view?usp=sharing\n","!gdown --id 1ZUCuYDOe4VVbZvNVZovpquaRQqqJQ639"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JveOJG8XH33s"},"outputs":[],"source":["!unzip img_cls_scenes_classification.zip"]},{"cell_type":"markdown","metadata":{"id":"EQeJEySoG_Qx"},"source":["## **1. Import libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_s_9iDJHNMJ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed = 59\n","set_seed(seed)"],"metadata":{"id":"J2EXyTIrxagC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vf2wyW6hH6LM"},"source":["## **2. Read dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aky_tAMuNT12"},"outputs":[],"source":["root_dir = 'scenes_classification'\n","train_dir = os.path.join(root_dir, 'train')\n","test_dir = os.path.join(root_dir, 'val')\n","\n","classes = {\n","    label_idx: class_name \\\n","        for label_idx, class_name in enumerate(\n","            sorted(os.listdir(train_dir))\n","        )\n","}\n","\n","X_train = []\n","y_train = []\n","X_test = []\n","y_test = []\n","for dataset_path in [train_dir, test_dir]:\n","    for label_idx, class_name in classes.items():\n","        class_dir = os.path.join(dataset_path, class_name)\n","        for img_filename in os.listdir(class_dir):\n","            img_path = os.path.join(class_dir, img_filename)\n","            if 'train' in dataset_path:\n","                X_train.append(img_path)\n","                y_train.append(label_idx)\n","            else:\n","                X_test.append(img_path)\n","                y_test.append(label_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ldki2MiNQaVi"},"outputs":[],"source":["classes"]},{"cell_type":"markdown","metadata":{"id":"W71YwGLtTb1C"},"source":["## **3. Train, val, test split**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDhW8oB3Sl3X"},"outputs":[],"source":["val_size = 0.2\n","is_shuffle = True\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_train, y_train,\n","    test_size=val_size,\n","    random_state=seed,\n","    shuffle=is_shuffle\n",")"]},{"cell_type":"markdown","metadata":{"id":"iXx3le_nTe7K"},"source":["## **4. Create pytorch dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKoGy1rhH7ol"},"outputs":[],"source":["class ScenesDataset(Dataset):\n","    def __init__(\n","        self,\n","        X, y,\n","        transform=None\n","    ):\n","        pass\n","\n","    def __len__(self):\n","        return None\n","\n","    def __getitem__(self, idx):\n","\n","        return None"]},{"cell_type":"markdown","metadata":{"id":"N87jYgtTVEaW"},"source":["## **5. Create data preprocessing function**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urcklIg-VKT_"},"outputs":[],"source":["def transform(img, img_size=(224, 224)):\n","\n","    return None"]},{"cell_type":"markdown","metadata":{"id":"BJWxpyFVVIQC"},"source":["## **6. Create dataloader**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r2INWkQ2UxCE"},"outputs":[],"source":["train_dataset = ScenesDataset(\n","    X_train, y_train,\n","    transform=transform\n",")\n","val_dataset = ScenesDataset(\n","    X_val, y_val,\n","    transform=transform\n",")\n","test_dataset = ScenesDataset(\n","    X_test, y_test,\n","    transform=transform\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MooDikjcWquF"},"outputs":[],"source":["train_batch_size = 64\n","test_batch_size = 8\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=train_batch_size,\n","    shuffle=True\n",")\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=test_batch_size,\n","    shuffle=False\n",")\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=test_batch_size,\n","    shuffle=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tC5_s8vvc23j"},"outputs":[],"source":["train_features, train_labels = next(iter(train_loader))\n","print(f'Feature batch shape: {train_features.size()}')\n","print(f'Labels batch shape: {train_labels.size()}')\n","img = train_features[0].permute(1, 2, 0)\n","label = train_labels[0].item()\n","plt.imshow(img)\n","plt.axis('off')\n","plt.title(f'Label: {classes[label]}')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"cqgmcSFifl01"},"source":["## **7. Create model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvNKVPY6mStX"},"outputs":[],"source":["class BottleneckBlock(nn.Module):\n","    def __init__(self, in_channels, growth_rate):\n","        super(BottleneckBlock, self).__init__()\n","        pass\n","\n","    def forward(self, x):\n","\n","        return None\n","\n","class DenseBlock(nn.Module):\n","    def __init__(self, num_layers, in_channels, growth_rate):\n","        super(DenseBlock, self).__init__()\n","        pass\n","\n","    def forward(self, x):\n","        return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMwlDUAOfoWi"},"outputs":[],"source":["class DenseNet(nn.Module):\n","    def __init__(self, num_blocks, growth_rate, num_classes):\n","        super(DenseNet, self).__init__()\n","        pass\n","\n","    def forward(self, x):\n","\n","        return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ltB3OKvvLjN"},"outputs":[],"source":["n_classes = len(list(classes.keys()))\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model = DenseNet(\n","    [6, 12, 24, 16],\n","    growth_rate=32,\n","    num_classes=n_classes\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaHaED-Pv4Z8"},"outputs":[],"source":["model.eval()\n","\n","dummy_tensor = torch.randn(1, 3, 224, 224).to(device)\n","\n","with torch.no_grad():\n","    output = model(dummy_tensor)\n","\n","print('Output shape:', output.shape)"]},{"cell_type":"markdown","metadata":{"id":"BwUyHR5Ry8Ma"},"source":["## **8. Training**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6yK8gbkEjY4"},"outputs":[],"source":["def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    losses = []\n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            losses.append(loss.item())\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    loss = sum(losses) / len(losses)\n","    acc = correct / total\n","\n","    return loss, acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lHlJ41gzlD73"},"outputs":[],"source":["def fit(\n","    model,\n","    train_loader,\n","    val_loader,\n","    criterion,\n","    optimizer,\n","    device,\n","    epochs\n","):\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(epochs):\n","        batch_train_losses = []\n","\n","        model.train()\n","        for idx, (inputs, labels) in enumerate(train_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            batch_train_losses.append(loss.item())\n","\n","        train_loss = sum(batch_train_losses) / len(batch_train_losses)\n","        train_losses.append(train_loss)\n","\n","        val_loss, val_acc = evaluate(\n","            model, val_loader,\n","            criterion, device\n","        )\n","        val_losses.append(val_loss)\n","\n","        print(f'EPOCH {epoch + 1}:\\tTrain loss: {train_loss:.4f}\\tVal loss: {val_loss:.4f}')\n","\n","    return train_losses, val_losses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RxIchZovy-nN"},"outputs":[],"source":["lr = 1e-3\n","epochs = 100\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(\n","    model.parameters(),\n","    lr=lr\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fcz64qrvni-6","scrolled":false},"outputs":[],"source":["train_losses, val_losses = fit(\n","    model,\n","    train_loader,\n","    val_loader,\n","    criterion,\n","    optimizer,\n","    device,\n","    epochs\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0KLZhQh74fG"},"outputs":[],"source":["fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n","ax[0].plot(train_losses)\n","ax[0].set_title('Training Loss')\n","ax[0].set_xlabel('Epoch')\n","ax[0].set_ylabel('Loss')\n","ax[1].plot(val_losses, color='orange')\n","ax[1].set_title('Val Loss')\n","ax[1].set_xlabel('Epoch')\n","ax[1].set_ylabel('Loss')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gQtRoAhDy9NO"},"source":["## **9. Evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRiWE-wFqdrp"},"outputs":[],"source":["val_loss, val_acc = evaluate(\n","    model,\n","    val_loader,\n","    criterion,\n","    device\n",")\n","test_loss, test_acc = evaluate(\n","    model,\n","    test_loader,\n","    criterion,\n","    device\n",")\n","\n","print('Evaluation on val/test dataset')\n","print('Val accuracy: ', val_acc)\n","print('Test accuracy: ', test_acc)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python [conda env:thangdd_env] *","language":"python","name":"conda-env-thangdd_env-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}